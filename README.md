# ðŸ§  DocMind AI

## Secure RAGâ€‘Powered Document Intelligence Platform

<p align="left">
  <b>Enterpriseâ€‘grade Retrievalâ€‘Augmented Generation (RAG)</b><br/>
  Multiâ€‘PDF â€¢ Secure â€¢ Explainable â€¢ Productionâ€‘oriented
</p>

---

## ðŸš€ What is DocMind AI?

**DocMind AI** is a **secure, productionâ€‘ready Retrievalâ€‘Augmented Generation (RAG) system** that allows users to upload multiple PDF documents and ask naturalâ€‘language questions with **answers grounded strictly in document context**.

This project is intentionally designed to look, feel, and behave like a **real internal enterprise AI system**, not a demo chatbot.

---

## ðŸŽ¯ Why Recruiters Love This Project

âœ… Real RAG architecture (not promptâ€‘stuffing)
âœ… Vector database with Pinecone (serverless)
âœ… LLaMAâ€‘3.1 inference via Groq (low latency)
âœ… Secure authentication & roleâ€‘based access
âœ… Explainable AI with source attribution
âœ… Costâ€‘aware design (caching + hashing)

> ðŸ’¡ This project demonstrates **LLM system engineering**, not just API usage.

---

## ðŸ§  Live Architecture Overview

```text
User
 â†“
Streamlit UI
 â†“
Authentication Layer (SHAâ€‘256)
 â†“
PDF Upload
 â†“
Text Chunking (Recursive)
 â†“
Embeddings (MiniLM)
 â†“
Pinecone Vector DB (Serverless)
 â†“
Context Retrieval (Topâ€‘K)
 â†“
LLaMAâ€‘3.1 via Groq
 â†“
Grounded Answer + Sources
```

---

## âœ¨ Feature Showcase

### ðŸ“š Multiâ€‘PDF RAG

Upload **multiple PDFs** and query them simultaneously.

### ðŸ” Semantic Search

Dense vector similarity using **Pinecone**.

### ðŸ“Œ Explainable AI

Every answer includes:

* Source document
* Page number
* Content preview

### ðŸ” Secure by Design

* Roleâ€‘based authentication
* Password hashing (SHAâ€‘256)
* Environmentâ€‘based secrets

### â™»ï¸ Smart Caching

* File hashing prevents reâ€‘embedding
* Faster queries
* Reduced cost

---

## âš™ï¸ Tech Stack

| Layer      | Technology              |
| ---------- | ----------------------- |
| UI         | Streamlit               |
| LLM        | LLaMAâ€‘3.1â€‘8B (Groq)     |
| Framework  | LangChain               |
| Embeddings | MiniLMâ€‘L6â€‘v2            |
| Vector DB  | Pinecone (Serverless)   |
| Docs       | PyPDFLoader             |
| Auth       | SHAâ€‘256 + Session State |

---

## ðŸ” Access & Demo Policy (Important)

> âš ï¸ **Pinecone vector storage is intentionally restricted**

This project uses a **persistent Pinecone index**, which:

* Incurs cost
* Stores embedded document data
* Is shared across sessions

### Therefore:

âŒ Pinecone credentials are **not public**
âŒ Open deployment is **intentionally disabled**
âœ… **Live demo access is provided on request**

---

## ðŸ“© Request a Demo / Interview Walkthrough

If you are a **recruiter, interviewer, or hiring manager**, I can:

* Grant **temporary Pinecone access**
* Walk through **architecture & design choices**
* Explain **scalability, cost, and security tradeâ€‘offs**
* Demonstrate **realâ€‘time document intelligence**

### ðŸ‘¤ Author

**Yash Handa**
ðŸ“§ Email: *hyash2455@gmail.com*
ðŸ”— LinkedIn: *www.linkedin.com/in/yashhanda18*

> ðŸ”’ Access is provided strictly for evaluation and interview purposes.

---

## ðŸš§ Future Enhancements

* Multiâ€‘tenant namespaces
* Metadataâ€‘aware retrieval
* Hybrid (BM25 + dense) search
* Streaming responses
* OCR for scanned PDFs
* RBAC per document
